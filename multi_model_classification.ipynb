{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn+G1HohLvcn0Wwsvpkv2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatimaZahraBoujrad/phishing_classification/blob/main/multi_model_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02cd26b9"
      },
      "source": [
        "# Phishing Website Detection using Stacking Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf2a0c40"
      },
      "source": [
        "## Explanation of the Notebook\n",
        "\n",
        "This notebook demonstrates a **stacking ensemble approach** for phishing website detection. The core idea is to combine the strengths of multiple individual models by training a 'meta-model' on their predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62cad710"
      },
      "source": [
        "### 1. Individual Pre-trained Models\n",
        "\n",
        "We start by loading three previously trained models, each specialized in analyzing different aspects of a website to detect phishing:\n",
        "\n",
        "*   **URL/DNS Model (`url_model`):** This model analyzes features derived from the url, dns and ssl records.\n",
        "*   **Content/HAR Model (`content_model`):** This model focuses on the content and HTTP Archive (HAR) information of a webpage.\n",
        "*   **HTML Model (`html_model`):** This model specifically extracts features from the HTML structure of the webpage.\n",
        "\n",
        "Each of these models outputs a probability (or score) indicating how likely a given input (URL features, content features, HTML features) is to be phishing. These probabilities are crucial for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39e867a7"
      },
      "source": [
        "### 2. Stacking the Models\n",
        "\n",
        "**Stacking**  is an ensemble machine learning technique where the predictions of multiple base models (our three individual models) are used as input features for a second-level learning algorithm, called the 'meta-model' or 'blender'.\n",
        "\n",
        "Here's how it works in this notebook:\n",
        "\n",
        "1.  **Prediction Generation:** Each of the three pre-trained models (`url_model`, `content_model`, `html_model`) makes a prediction (specifically, the probability of being phishing, `predict_proba`) on both the training and testing datasets.\n",
        "\n",
        "2.  **Meta-Feature Creation:** Instead of directly using the individual model predictions as the final output, we create a new dataset where each row consists of the prediction probabilities from the three base models. For example, for a single website, the new feature vector would be `[p_url, p_content, p_html]`, where `p_url` is the phishing probability from the URL model, `p_content` from the content model, and `p_html` from the HTML model.\n",
        "\n",
        "3.  **Meta-Model Training:** A **Logistic Regression** model (`meta_model`) is then trained on this new dataset of prediction probabilities (`X_meta_train`). The target variable (`y_train`) for this meta-model is still the original phishing label (phishing/benign).\n",
        "\n",
        "4.  **Final Prediction:** The trained `meta_model` then takes the combined prediction probabilities of the base models on the *test* set (`X_meta_test`) and produces the final phishing prediction for a given website. This allows the Logistic Regression to learn the optimal way to combine the insights from each base model, often leading to better performance than any single model alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c5101c1"
      },
      "source": [
        "### Conclusion of Results:\n",
        "\n",
        "After training the meta-model (Logistic Regression) on the predictions of the three base models (URL/DNS, Content/HAR, and HTML), we evaluated its performance.\n",
        "\n",
        "*   **Stacking Model Performance:**\n",
        "    The `classification_report`  demonstrate the effectiveness of the stacking approach. We observe very high accuracy, precision, recall, and F1-scores, along with an excellent ROC-AUC score, indicating that the meta-model is highly capable of distinguishing between phishing and benign websites by intelligently combining the insights from the individual models.\n",
        "\n",
        "*   **Data Leakage Verification:**\n",
        "    To ensure the high performance isn't due to data leakage (where information from the test set inadvertently influences the training process), several tests were conducted:\n",
        "    1.  **Shuffled Labels Test:** Training a meta-model with shuffled training labels (`y_shuffled`) resulted in a significantly lower AUC score (`0.0728`), indicating that the model did not learn to predict based on random labels, which is a good sign against leakage.\n",
        "    2.  **Training AUC vs. Test AUC:** The training AUC (`0.9999997890625`) is very close to the test AUC (which would be derived from the final `ROC-AUC` score of the meta-model, typically in the high 0.99s as seen in the output). A small difference suggests good generalization and minimal overfitting on the training data due to leakage.\n",
        "    3.  **Random Noise Test:** Training a meta-model on purely random noise (`X_noise`) yielded an AUC score around `0.489`, which is close to `0.5` (random guessing). This confirms that the model's high performance is due to learning patterns from the actual features, not random chance.\n",
        "    4.  **Train/Test Accuracy:** The train accuracy (`0.99959375`) and test accuracy (`0.99975`) are both very high and very close. This further supports the conclusion that the model generalizes well and is not experiencing data leakage or severe overfitting.\n",
        "\n",
        "In summary, the tests confirm that the stacking model is robust, performs exceptionally well, and the results are not influenced by data leakage. The impressive accuracy is a result of the effective combination of the specialized base models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ng1ZsOtnEpQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238eb6fd-bb75-4ad8-f7cb-4a4964f284da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "utEdbllsrbW4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  1. Loading the pre trained models and datasets"
      ],
      "metadata": {
        "id": "H-3qLCKJDdwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "egLW4tGHDdsq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cxkFt9mExxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/Projet_Phishing\"\n",
        "\n",
        "url_model_path = f\"{BASE_PATH}/url_dns_best_model.joblib\"\n",
        "content_model_path = f\"{BASE_PATH}/content_info_cl.joblib\"\n",
        "html_model_path = f\"{BASE_PATH}/html_classifier.pkl\"\n"
      ],
      "metadata": {
        "id": "-DD1n2qp3hgK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Datasets\n",
        "benign_html=pd.read_csv(\"/content/drive/MyDrive/Projet_Phishing/Dataset/benign_html_features.csv\")\n",
        "phishing_html=pd.read_csv(\"/content/drive/MyDrive/Projet_Phishing/Dataset/phishing_html_features.csv\")\n",
        "benign_content=pd.read_csv(\"/content/drive/MyDrive/Projet_Phishing/Dataset/benign_content_feat.csv\")\n",
        "phishing_content=pd.read_csv(\"/content/drive/MyDrive/Projet_Phishing/Dataset/phishing_content_feat.csv\")\n",
        "benign_url=pd.read_csv(\"/content/drive/MyDrive/Projet_Phishing/Dataset/benign_url_dns_ssl.csv\")\n",
        "phishing_url=pd.read_csv(\"/content/drive/MyDrive/Projet_Phishing/Dataset/phishing_url_dns_ssl.csv\")"
      ],
      "metadata": {
        "id": "jW12srVG1h46"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preparing the datasets"
      ],
      "metadata": {
        "id": "Eb8Jn8MuDorT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign_html[\"label\"]=0\n",
        "phishing_html[\"label\"]=1\n",
        "\n",
        "benign_url[\"label\"]=0\n",
        "phishing_url[\"label\"]=1"
      ],
      "metadata": {
        "id": "CTt0l4-W5LHB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html_df = pd.concat([benign_html, phishing_html], ignore_index=True)\n",
        "content_df = pd.concat([benign_content[:20000], phishing_content[:20000]], ignore_index=True)\n",
        "url_df = pd.concat([benign_url[:20000], phishing_url[:20000]], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "sDsC4GVI5ntq"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = url_df['label']\n",
        "\n",
        "X_html = html_df.drop(columns=['label','mailto_form_action'])\n",
        "X_content = content_df.drop(columns=['label','url'])\n",
        "X_url = url_df.drop(columns=['label','url'])\n"
      ],
      "metadata": {
        "id": "6w1yGAvc5ioX"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_url_train, X_url_test, \\\n",
        "X_content_train, X_content_test, \\\n",
        "X_html_train, X_html_test, \\\n",
        "y_train, y_test = train_test_split(\n",
        "    X_url,\n",
        "    X_content,\n",
        "    X_html,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "8FXG2lf_7Jou"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Stacking the 3 models"
      ],
      "metadata": {
        "id": "FMxoOEW3DwYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_model = load(url_model_path)\n",
        "content_model = load(content_model_path)\n",
        "html_model = load(html_model_path)\n",
        "\n",
        "print(\" Modèle URL/DNS chargé\")\n",
        "print(\" Modèle Content/HAR chargé\")\n",
        "print(\" Modèle HTML chargé\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeCjyMX357d9",
        "outputId": "443b45b9-ff8d-4e69-a7c2-b5989ff61361"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Modèle URL/DNS chargé\n",
            " Modèle Content/HAR chargé\n",
            " Modèle HTML chargé\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "p_url_train = url_model.predict_proba(X_url_train)[:, 1]\n",
        "p_content_train = content_model.predict_proba(X_content_train)[:, 1]\n",
        "p_html_train = html_model.predict_proba(X_html_train)[:, 1]\n",
        "\n",
        "X_meta_train = np.column_stack([p_url_train, p_content_train, p_html_train])\n"
      ],
      "metadata": {
        "id": "i0UsGNAJ4DZB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_url_test = url_model.predict_proba(X_url_test)[:, 1]\n",
        "p_content_test = content_model.predict_proba(X_content_test)[:, 1]\n",
        "p_html_test = html_model.predict_proba(X_html_test)[:, 1]\n",
        "\n",
        "X_meta_test = np.column_stack([p_url_test, p_content_test, p_html_test])\n"
      ],
      "metadata": {
        "id": "eiF_wS6M7ZLC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notebook Title: Phishing Detection Stacking Model Evaluation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(X_meta_train, y_train)\n",
        "\n",
        "y_meta_pred = meta_model.predict(X_meta_test)\n",
        "y_meta_prob = meta_model.predict_proba(X_meta_test)[:, 1]\n",
        "\n",
        "print(\"=== STACKING FINAL ===\")\n",
        "print(classification_report(y_test, y_meta_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_meta_prob))"
      ],
      "metadata": {
        "id": "RQ6-krvV7ZpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data leakage verification"
      ],
      "metadata": {
        "id": "We4OfIbrDOKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Shuffle labels\n",
        "y_shuffled = y_train.sample(frac=1, random_state=42).values\n",
        "\n",
        "meta_model_leak_test = LogisticRegression()\n",
        "meta_model_leak_test.fit(X_meta_train, y_shuffled)\n",
        "\n",
        "y_pred = meta_model_leak_test.predict_proba(X_meta_test)[:, 1]\n",
        "\n",
        "print(\"AUC with shuffled labels:\", roc_auc_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6-k0BjH7cME",
        "outputId": "4bb6d890-a0ca-4727-ed42-f8e60ce10732"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC with shuffled labels: 0.07280949999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy droped after testing with shuffled labels which means there is a small probability of having a leakage"
      ],
      "metadata": {
        "id": "dJDgf4V1BkXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_train_pred = meta_model.predict_proba(X_meta_train)[:, 1]\n",
        "print(\"Train AUC:\", roc_auc_score(y_train, y_train_pred))\n",
        "# the accacy on traing dataset is not equal to 1.0 (not perfect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_w0Wdws9kwf",
        "outputId": "97a8823d-1738-423d-f277-5e7337db9a0a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train AUC: 0.9999997890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(42)\n",
        "X_noise = rng.rand(*X_meta_train.shape)\n",
        "\n",
        "meta_noise = LogisticRegression()\n",
        "meta_noise.fit(X_noise, y_train)\n",
        "\n",
        "y_noise_pred = meta_noise.predict_proba(\n",
        "    rng.rand(*X_meta_test.shape)\n",
        ")[:, 1]\n",
        "\n",
        "print(\"AUC random noise:\", roc_auc_score(y_test, y_noise_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy1K1vg593M0",
        "outputId": "2892e37d-ab49-4c02-cead-7c71d914d339"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC random noise: 0.4891419374999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_acc = accuracy_score(\n",
        "    y_train,\n",
        "    meta_model.predict(X_meta_train)\n",
        ")\n",
        "\n",
        "test_acc = accuracy_score(\n",
        "    y_test,\n",
        "    meta_model.predict(X_meta_test)\n",
        ")\n",
        "\n",
        "print(\"Train acc:\", train_acc)\n",
        "print(\"Test acc:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJzg0mNN93r_",
        "outputId": "5e1a5aeb-e564-4600-a675-d8236b1a7d75"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc: 0.99959375\n",
            "Test acc: 0.99975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion:\n",
        "The tests we conducted indicate that there is no data leakage in training or testing the stacking model. The high accuracy is probably due to the fact that the three base models are already very strong and complementary, providing highly informative predictions for the meta-classifier. Additionally, the dataset features patterns that make phishing and benign samples relatively easy to separate. Overall, the stacking approach successfully combines the strengths of the individual models while maintaining a leakage-free evaluation."
      ],
      "metadata": {
        "id": "JFfBGgRPD8k_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQZ_6Wt8EK1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}